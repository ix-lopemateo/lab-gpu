{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13aba6e-56cc-4d3d-8d05-967e0ec26bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "8.11 ms ± 53.9 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.3 ms ± 4.58 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.5 ms ± 171 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "# CÓDIGO ORIGINAL\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "\n",
    "# Python plain implementation w/ numba \n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a*x[i]*x[i] + b*y[i] + c\n",
    "    return z\n",
    "\n",
    "# Numpy ufunc\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# size of the vectors\n",
    "size = 5_000_000\n",
    "\n",
    "# allocating and populating the vectors\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "c_cpu = np.zeros(size)\n",
    "\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10\n",
    "\n",
    "# Printing input values\n",
    "#print(a_cpu)\n",
    "#print(b_cpu)\n",
    "# Random function in Numpy always use float64\n",
    "print(a_cpu.dtype)\n",
    "\n",
    "c_cpu = grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "\n",
    "# Evaluating the time\n",
    "\n",
    "# Numba Python: huge improvement, better that numpy code\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# w/ a numpy ufunc manually coded\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# using the general numpy ufunc \n",
    "%timeit -n 5 -r 2 a*a_cpu**2 + b*b_cpu + c \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240fd740-5e71-48fe-9bcd-284113cf3d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LIBRERÍA CUPY\n",
    "\n",
    "# Preparación para GPU\n",
    "import cupy as cp\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "# Pasamos a float32 (más realista para GPU)\n",
    "a_cpu_32 = a_cpu.astype(np.float32)\n",
    "b_cpu_32 = b_cpu.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f54b12-7e97-4534-aa3a-303bc1a83b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy CON copia (CPU↔GPU + cálculo):\n",
      "cupy_con_copia      :    CPU:  7723.900 us   +/- 38.556 (min:  7685.202 / max:  7791.935) us     GPU-0:  7728.864 us   +/- 38.642 (min:  7689.888 / max:  7796.576) us\n"
     ]
    }
   ],
   "source": [
    "# 1A) CUPY CON COPIA\n",
    "def cupy_con_copia(x_cpu, y_cpu, a, b, c):\n",
    "    # Copia CPU → GPU\n",
    "    x_gpu = cp.asarray(x_cpu)\n",
    "    y_gpu = cp.asarray(y_cpu)\n",
    "    \n",
    "    # Cálculo en GPU (ufuncs)\n",
    "    z_gpu = a * x_gpu**2 + b * y_gpu + c\n",
    "    \n",
    "    # Copia GPU → CPU\n",
    "    return cp.asnumpy(z_gpu)\n",
    "\n",
    "print(\"CuPy CON copia (CPU↔GPU + cálculo):\")\n",
    "print(benchmark(\n",
    "    cupy_con_copia,\n",
    "    (a_cpu_32, b_cpu_32, a, b, c),\n",
    "    n_repeat=5\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79252985-dcd9-4a9c-b23f-2c51e4b4ae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CuPy SIN copia (solo cálculo en GPU):\n",
      "cupy_sin_copia      :    CPU:    97.619 us   +/-  1.531 (min:    95.587 / max:    99.491) us     GPU-0:   904.064 us   +/-  1.213 (min:   902.144 / max:   905.216) us\n"
     ]
    }
   ],
   "source": [
    "# 1B) CUPY SIN COPIA\n",
    "a_gpu_32 = cp.asarray(a_cpu_32)\n",
    "b_gpu_32 = cp.asarray(b_cpu_32)\n",
    "\n",
    "def cupy_sin_copia(x_gpu, y_gpu, a, b, c):\n",
    "    return a * x_gpu**2 + b * y_gpu + c\n",
    "\n",
    "\n",
    "print(\"\\nCuPy SIN copia (solo cálculo en GPU):\")\n",
    "print(benchmark(\n",
    "    cupy_sin_copia,\n",
    "    (a_gpu_32, b_gpu_32, a, b, c),\n",
    "    n_repeat=5\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbecf40a-3965-46a7-adf0-ae80b89eec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LIBRERÍA NUMBA CUDA\n",
    "\n",
    "from numba import vectorize, float32\n",
    "\n",
    "@vectorize([float32(float32, float32, float32, float32, float32)],\n",
    "           target='cuda')\n",
    "def grade2_vector_cuda(x, y, a, b, c):\n",
    "    return a * x * x + b * y + c\n",
    "\n",
    "a_cpu_32 = a_cpu.astype(np.float32)\n",
    "b_cpu_32 = b_cpu.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17cf88d7-527f-4c5c-83ab-27286d5a44c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba CUDA CON copia:\n",
      "numba_con_copia     :    CPU:  9647.698 us   +/- 1658.731 (min:  7485.653 / max: 11543.998) us     GPU-0:  9655.827 us   +/- 1659.743 (min:  7492.384 / max: 11552.000) us\n"
     ]
    }
   ],
   "source": [
    "# 2A) NUMBA CUDA CON COPIA\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "def numba_con_copia(x_cpu, y_cpu, a, b, c):\n",
    "    return grade2_vector_cuda(x_cpu, y_cpu, a, b, c)\n",
    "\n",
    "print(\"Numba CUDA CON copia:\")\n",
    "print(benchmark(\n",
    "    numba_con_copia,\n",
    "    (a_cpu_32, b_cpu_32, a, b, c),\n",
    "    n_repeat=5\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aad55b2-0c0a-4600-8f91-56a07718e324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numba CUDA SIN copia:\n",
      "numba_sin_copia     :    CPU:  1512.934 us   +/- 650.415 (min:   931.589 / max:  2313.732) us     GPU-0:  1630.355 us   +/- 560.082 (min:  1127.424 / max:  2320.544) us\n"
     ]
    }
   ],
   "source": [
    "# 2B) NUMBA CUDA SIN COPIA\n",
    "a_gpu_32 = cp.asarray(a_cpu_32)\n",
    "b_gpu_32 = cp.asarray(b_cpu_32)\n",
    "\n",
    "def numba_sin_copia(x_gpu, y_gpu, a, b, c):\n",
    "    return grade2_vector_cuda(x_gpu, y_gpu, a, b, c)\n",
    "\n",
    "print(\"\\nNumba CUDA SIN copia:\")\n",
    "print(benchmark(\n",
    "    numba_sin_copia,\n",
    "    (a_gpu_32, b_gpu_32, a, b, c),\n",
    "    n_repeat=5\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105a016d-4043-4195-99a0-4201d61e81c4",
   "metadata": {},
   "source": [
    "# ANÁLISIS DE LOS RESULTADOS\n",
    "Este ejercicio permite estudiar la ejecución del cálculo de segundo grado usando CPU, CuPy y Numba CUDA, tanto copiando los datos entre CPU y GPU como manteniéndolos en la memoria de la GPU.\n",
    "\n",
    "Como referencia en CPU, la implementación con Numba (@njit) presenta el mejor rendimiento, con tiempos en torno a 8 ms, mientras que las versiones basadas en ufuncs de NumPy se sitúan alrededor de 18 ms.\n",
    "\n",
    "En el caso de CuPy con copia de datos, el tiempo total se mantiene en el orden de 7–8 ms, similar al de la ejecución en CPU. Esto indica que el coste de transferencia de datos entre CPU y GPU domina el tiempo total y anula las ventajas del paralelismo de la GPU para este tipo de operación.\n",
    "\n",
    "Cuando los datos se mantienen en la memoria de la GPU, el tiempo reportado en CPU (del orden de 100 μs) corresponde principalmente al lanzamiento del kernel y a la gestión de la ejecución asíncrona, mientras que el tiempo reportado en GPU (del orden de 0.9 ms) representa el tiempo real de cálculo del vector en la GPU. Este último debe compararse con el tiempo de cálculo en CPU, que es del orden de 8 ms. Esto pone de manifiesto que el cálculo en sí es significativamente más rápido en GPU que en CPU. \n",
    "\n",
    "Resultados similares se observan con Numba CUDA. Cuando la copia de datos se realiza implícitamente en cada llamada, los tiempos se sitúan en torno a 9–10 ms, nuevamente ralentizados por la transferencia de memoria. Sin embargo, cuando los datos ya están en la GPU, el tiempo de ejecución se reduce a aproximadamente 1.5 ms, mostrando una mejora clara frente a la CPU, aunque ligeramente inferior a la obtenida con CuPy debido a que los kernels generados por Numba son menos optimizados.\n",
    "\n",
    "En conjunto, estos resultados muestran que el uso de GPU solo resulta beneficioso cuando se minimizan las transferencias de datos entre CPU y GPU, y que CuPy ofrece el mejor rendimiento cuando se trabaja con datos ya en la GPU, mientras que Numba proporciona una alternativa flexible con un coste ligeramente superior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
